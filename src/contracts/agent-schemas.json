{
  "$schema": "./schemas/agent-schemas.schema.json",
  "contractVersion": "1.0.0",
  "version": "2024-11-24",
  "label": "Erosolar CLI Agent Configuration Schema",
  "description": "Centralized configuration for all agents, models, providers, and capabilities",

  "providers": [
    {
      "id": "openai",
      "label": "OpenAI",
      "description": "OpenAI GPT models including GPT-5 series",
      "envVars": {
        "apiKey": "OPENAI_API_KEY"
      },
      "capabilities": ["chat", "reasoning", "tools", "streaming"]
    },
    {
      "id": "anthropic",
      "label": "Anthropic",
      "description": "Anthropic Claude models including Sonnet, Opus, and Haiku",
      "envVars": {
        "apiKey": "ANTHROPIC_API_KEY"
      },
      "capabilities": ["chat", "reasoning", "tools", "streaming"]
    },
    {
      "id": "deepseek",
      "label": "DeepSeek",
      "description": "DeepSeek reasoning and chat models",
      "envVars": {
        "apiKey": "DEEPSEEK_API_KEY"
      },
      "capabilities": ["chat", "reasoning", "tools", "streaming"]
    },
    {
      "id": "xai",
      "label": "xAI",
      "description": "xAI Grok models for coding and reasoning",
      "envVars": {
        "apiKey": "XAI_API_KEY"
      },
      "capabilities": ["chat", "reasoning", "tools", "streaming"]
    },
    {
      "id": "google",
      "label": "Google",
      "description": "Google Gemini models with multimodal capabilities",
      "envVars": {
        "apiKey": "GEMINI_API_KEY"
      },
      "capabilities": ["chat", "reasoning", "tools", "streaming", "multimodal"]
    },
    {
      "id": "ollama",
      "label": "Ollama (Local)",
      "description": "Run open-weight models locally via Ollama (Llama, Qwen, Mistral, etc.)",
      "envVars": {},
      "capabilities": ["chat", "tools", "streaming"]
    }
  ],

  "models": [
    {
      "id": "gpt-4o",
      "label": "gpt-4o",
      "provider": "openai",
      "description": "OpenAI GPT-4o - fast, capable model for coding and general tasks.",
      "capabilities": ["chat", "reasoning", "tools", "streaming"]
    },
    {
      "id": "gpt-4o-mini",
      "label": "gpt-4o-mini",
      "provider": "openai",
      "description": "OpenAI GPT-4o Mini - lightweight and fast for quick tasks.",
      "capabilities": ["chat", "tools", "streaming"]
    },
    {
      "id": "gpt-4.1",
      "label": "gpt-4.1",
      "provider": "openai",
      "description": "OpenAI GPT-4.1 - latest GPT-4 series model.",
      "capabilities": ["chat", "reasoning", "tools", "streaming"]
    },
    {
      "id": "gpt-5.1-codex-mini",
      "label": "gpt-5.1-codex-mini",
      "provider": "openai",
      "description": "Lightweight GPT-5.1 Codex for fast iteration and quick tasks.",
      "reasoningEffort": "low",
      "capabilities": ["chat", "reasoning", "tools", "streaming"]
    },
    {
      "id": "gpt-5.1-codex",
      "label": "gpt-5.1-codex",
      "provider": "openai",
      "description": "Optimized for Erosolar Code with the latest coding weights from OpenAI.",
      "reasoningEffort": "medium",
      "capabilities": ["chat", "reasoning", "tools", "streaming"]
    },
    {
      "id": "codex-max",
      "label": "codex-max",
      "provider": "openai",
      "description": "OpenAI Codex Max for the highest throughput reasoning and coding runs.",
      "reasoningEffort": "high",
      "capabilities": ["chat", "reasoning", "tools", "streaming"]
    },
    {
      "id": "gpt-5.1",
      "label": "gpt-5.1",
      "provider": "openai",
      "description": "Balanced reasoning model when you need equal parts code and analysis.",
      "reasoningEffort": "medium",
      "capabilities": ["chat", "reasoning", "tools", "streaming"]
    },
    {
      "id": "gpt-5-pro",
      "label": "gpt-5-pro",
      "provider": "openai",
      "description": "OpenAI's flagship GPT-5 Pro for maximum depth and planning.",
      "reasoningEffort": "medium",
      "capabilities": ["chat", "reasoning", "tools", "streaming"]
    },
    {
      "id": "gpt-5-mini",
      "label": "gpt-5-mini",
      "provider": "openai",
      "description": "GPT-5 Mini with faster turnarounds while staying code-aware.",
      "reasoningEffort": "medium",
      "capabilities": ["chat", "reasoning", "tools", "streaming"]
    },
    {
      "id": "gpt-5-nano",
      "label": "gpt-5-nano",
      "provider": "openai",
      "description": "Ultra-responsive GPT-5 Nano tuned for edits and quick summaries.",
      "reasoningEffort": "medium",
      "capabilities": ["chat", "tools", "streaming"]
    },
    {
      "id": "o3-pro",
      "label": "o3-pro",
      "provider": "openai",
      "description": "OpenAI o3-pro - most capable reasoning model for complex multi-step problems.",
      "reasoningEffort": "high",
      "capabilities": ["chat", "reasoning", "tools", "streaming"]
    },
    {
      "id": "o3",
      "label": "o3",
      "provider": "openai",
      "description": "OpenAI o3 - advanced reasoning model with extended thinking.",
      "reasoningEffort": "high",
      "capabilities": ["chat", "reasoning", "tools", "streaming"]
    },
    {
      "id": "o3-mini",
      "label": "o3-mini",
      "provider": "openai",
      "description": "OpenAI o3-mini - fast reasoning model with strong performance.",
      "reasoningEffort": "medium",
      "capabilities": ["chat", "reasoning", "tools", "streaming"]
    },
    {
      "id": "o1-pro",
      "label": "o1-pro",
      "provider": "openai",
      "description": "OpenAI o1-pro - professional tier reasoning for complex analysis and coding.",
      "reasoningEffort": "high",
      "capabilities": ["chat", "reasoning", "tools", "streaming"]
    },
    {
      "id": "o1",
      "label": "o1",
      "provider": "openai",
      "description": "OpenAI o1 - reasoning model optimized for STEM and code.",
      "reasoningEffort": "high",
      "capabilities": ["chat", "reasoning", "tools", "streaming"]
    },
    {
      "id": "o1-mini",
      "label": "o1-mini",
      "provider": "openai",
      "description": "OpenAI o1-mini - lightweight reasoning model for quick problem solving.",
      "reasoningEffort": "medium",
      "capabilities": ["chat", "reasoning", "tools", "streaming"]
    },
    {
      "id": "claude-3-5-sonnet-20241022",
      "label": "claude-3.5-sonnet",
      "provider": "anthropic",
      "description": "Anthropic Claude 3.5 Sonnet - balanced performance for coding tasks.",
      "temperature": 0.7,
      "maxTokens": 8192,
      "capabilities": ["chat", "reasoning", "tools", "streaming"]
    },
    {
      "id": "claude-sonnet-4-5-20250929",
      "label": "sonnet-4.5",
      "provider": "anthropic",
      "description": "Anthropic Sonnet 4.5 tuned for deeper planning across large repositories.",
      "temperature": 0.7,
      "maxTokens": 4096,
      "capabilities": ["chat", "reasoning", "tools", "streaming"]
    },
    {
      "id": "claude-opus-4-20250514",
      "label": "opus-4",
      "provider": "anthropic",
      "description": "Anthropic Opus 4.1 for the richest Claude reasoning runs.",
      "temperature": 0.7,
      "maxTokens": 4096,
      "capabilities": ["chat", "reasoning", "tools", "streaming"]
    },
    {
      "id": "claude-haiku-4-5-20251001",
      "label": "haiku-4.5",
      "provider": "anthropic",
      "description": "Anthropic Haiku 4.5 focused on latency-sensitive workflows.",
      "temperature": 0.5,
      "maxTokens": 4096,
      "capabilities": ["chat", "tools", "streaming"]
    },
    {
      "id": "deepseek-reasoner",
      "label": "deepseek-reasoner",
      "provider": "deepseek",
      "description": "DeepSeek Reasoner for chain-of-thought exploration with tool depth.",
      "capabilities": ["chat", "reasoning", "tools", "streaming"]
    },
    {
      "id": "deepseek-chat",
      "label": "deepseek-chat",
      "provider": "deepseek",
      "description": "DeepSeek Chat for faster interactive editing and summarization.",
      "capabilities": ["chat", "tools", "streaming"]
    },
    {
      "id": "grok-4-1-fast-reasoning",
      "label": "grok-4-1-fast-reasoning",
      "provider": "xai",
      "description": "Grok-4.1 fast reasoning mode with improved performance and enhanced thinking capabilities.",
      "capabilities": ["chat", "reasoning", "tools", "streaming"]
    },
    {
      "id": "grok-4-1-fast-non-reasoning",
      "label": "grok-4-1-fast-non-reasoning",
      "provider": "xai",
      "description": "Grok-4.1 fast non-reasoning mode for lower latency without thinking.",
      "capabilities": ["chat", "tools", "streaming"]
    },
    {
      "id": "grok-4",
      "label": "grok-4",
      "provider": "xai",
      "description": "xAI Grok-4 for their highest quality coding and reasoning responses.",
      "capabilities": ["chat", "reasoning", "tools", "streaming"]
    },
    {
      "id": "grok-4-fast-reasoning",
      "label": "grok-4-fast-reasoning",
      "provider": "xai",
      "description": "Grok-4 fast reasoning mode when you need lower latency with thinking enabled.",
      "capabilities": ["chat", "reasoning", "tools", "streaming"]
    },
    {
      "id": "grok-4-fast-non-reasoning",
      "label": "grok-4-fast-non-reasoning",
      "provider": "xai",
      "description": "Grok-4 fast non reasoning variant for concise edits and summaries.",
      "capabilities": ["chat", "tools", "streaming"]
    },
    {
      "id": "grok-code-fast-1",
      "label": "grok-code-fast-1",
      "provider": "xai",
      "description": "xAI Grok Code Fast 1 tuned specifically for rapid coding assistance.",
      "capabilities": ["chat", "tools", "streaming"]
    },
    {
      "id": "gemini-2.5-pro",
      "label": "gemini-2.5-pro",
      "provider": "google",
      "description": "Google Gemini 2.5 Pro for multimodal deep reasoning with longer outputs.",
      "capabilities": ["chat", "reasoning", "tools", "streaming", "multimodal"]
    },
    {
      "id": "gemini-2.5-flash",
      "label": "gemini-2.5-flash",
      "provider": "google",
      "description": "Google Gemini 2.5 Flash for lower-latency edits and iterative coding.",
      "capabilities": ["chat", "tools", "streaming", "multimodal"]
    },
    {
      "id": "llama3.1:8b",
      "label": "llama3.1:8b",
      "provider": "ollama",
      "description": "Meta Llama 3.1 8B - Strong general purpose local model with 128K context",
      "capabilities": ["chat", "reasoning", "tools", "streaming"]
    },
    {
      "id": "llama3.2:3b",
      "label": "llama3.2:3b",
      "provider": "ollama",
      "description": "Meta Llama 3.2 3B - Efficient local model for quick responses",
      "capabilities": ["chat", "tools", "streaming"]
    },
    {
      "id": "qwen2.5:7b",
      "label": "qwen2.5:7b",
      "provider": "ollama",
      "description": "Alibaba Qwen 2.5 7B - Excellent multilingual model with strong Chinese support",
      "capabilities": ["chat", "reasoning", "tools", "streaming"]
    },
    {
      "id": "qwen2.5:14b",
      "label": "qwen2.5:14b",
      "provider": "ollama",
      "description": "Alibaba Qwen 2.5 14B - Larger variant with enhanced reasoning capabilities",
      "capabilities": ["chat", "reasoning", "tools", "streaming"]
    },
    {
      "id": "mistral:7b",
      "label": "mistral:7b",
      "provider": "ollama",
      "description": "Mistral 7B - Fast and efficient local model for general tasks",
      "capabilities": ["chat", "tools", "streaming"]
    },
    {
      "id": "deepseek-coder:6.7b",
      "label": "deepseek-coder:6.7b",
      "provider": "ollama",
      "description": "DeepSeek Coder 6.7B - Specialized for code generation and programming tasks",
      "capabilities": ["chat", "tools", "streaming"]
    },
    {
      "id": "codellama:7b",
      "label": "codellama:7b",
      "provider": "ollama",
      "description": "Meta Code Llama 7B - Code-focused variant of Llama optimized for programming",
      "capabilities": ["chat", "tools", "streaming"]
    }
  ],

  "profiles": [
    {
      "name": "agi-code",
      "label": "AGI Code",
      "description": "DeepSeek-powered coding specialist with advanced reasoning capabilities.",
      "defaultProvider": "deepseek",
      "defaultModel": "deepseek-reasoner",
      "systemPrompt": {
        "type": "rulebook"
      },
      "rulebook": {
        "file": "agents/agi-code.rules.json",
        "version": "2024-11-24",
        "contractVersion": "1.0.0",
        "description": "Deterministic coding workflow guardrails."
      },
      "metadata": {
        "primaryUseCase": "coding",
        "tags": ["coding", "deterministic", "rapid-edits"]
      }
    }
  ],

  "slashCommands": [
    {
      "command": "/model",
      "description": "Choose what model and reasoning effort to use",
      "category": "configuration"
    },
    {
      "command": "/approvals",
      "description": "Choose what Codex can do without approval",
      "category": "configuration"
    },
    {
      "command": "/review",
      "description": "Review current changes and find issues",
      "category": "diagnostics"
    },
    {
      "command": "/new",
      "description": "Start a new chat without closing the session",
      "category": "workspace"
    },
    {
      "command": "/init",
      "description": "Create AGENTS.md with instructions for Codex",
      "category": "workspace"
    },
    {
      "command": "/compact",
      "description": "Summarize conversation to prevent hitting the context limit",
      "category": "workspace"
    },
    {
      "command": "/undo",
      "description": "Undo the last turn (rewind/checkpoint helper)",
      "category": "workspace"
    },
    {
      "command": "/diff",
      "description": "Show git diff (including untracked files)",
      "category": "workspace"
    },
    {
      "command": "/mention",
      "description": "Mention a file or path (e.g., @src/app.ts)",
      "category": "workspace"
    },
    {
      "command": "/status",
      "description": "Show current session configuration and token usage",
      "category": "diagnostics"
    },
    {
      "command": "/mcp",
      "description": "List configured MCP tools",
      "category": "configuration"
    },
    {
      "command": "/logout",
      "description": "Log out of Codex (clear stored credentials)",
      "category": "configuration"
    },
    {
      "command": "/quit",
      "description": "Exit Codex",
      "category": "other"
    },
    {
      "command": "/exit",
      "description": "Exit Codex",
      "category": "other"
    },
    {
      "command": "/help",
      "description": "Show all available commands and keyboard shortcuts",
      "category": "other"
    },
    {
      "command": "/features",
      "description": "Toggle optional features (AlphaZero dual, metrics, MCP, etc.)",
      "category": "configuration"
    },
    {
      "command": "/learn",
      "description": "View and manage AlphaZero learned patterns and improvements",
      "category": "other"
    },
    {
      "command": "/improve",
      "description": "Run AlphaZero self-improvement (analyze, apply, dry-run)",
      "category": "other"
    },
    {
      "command": "/evolve",
      "description": "Self-evolution and optimization (analyze, start, stop, learn, fix, tokens, targets, optimize, guidelines, actions)",
      "category": "other"
    },
    {
      "command": "/test",
      "description": "Intelligent test flows (generate, bugs, ui, edge) - edge case detection and bug finding",
      "category": "other"
    },
    {
      "command": "/refresh-models",
      "description": "Auto-discover new models from configured providers",
      "category": "configuration"
    },
    {
      "command": "/secrets",
      "description": "Configure API keys",
      "category": "configuration"
    },
    {
      "command": "/tools",
      "description": "Enable or disable CLI tools and MCP servers",
      "category": "configuration"
    },
    {
      "command": "/thinking",
      "description": "Toggle thinking mode (balanced or extended)",
      "category": "configuration"
    },
    {
      "command": "/skills",
      "description": "List available SKILL.md packages and refresh the cache",
      "category": "workspace"
    },
    {
      "command": "/doctor",
      "description": "Check environment, secrets, and tool readiness",
      "category": "diagnostics"
    },
    {
      "command": "/checks",
      "description": "Run repo checks (npm test / npm run build / npm run lint)",
      "category": "diagnostics"
    },
    {
      "command": "/context",
      "description": "Refresh workspace snapshot (depth/excerpt overrides)",
      "category": "workspace"
    },
    {
      "command": "/sessions",
      "description": "Manage saved conversations, autosave, and session history",
      "category": "workspace"
    },
    {
      "command": "/provider",
      "description": "Switch to a different AI provider (e.g., /provider xai)",
      "category": "configuration"
    },
    {
      "command": "/providers",
      "description": "List all configured AI providers",
      "category": "configuration"
    },
    {
      "command": "/local",
      "description": "Manage local/air-gapped LLM servers (Ollama, LM Studio, etc.)",
      "category": "configuration"
    },
    {
      "command": "/rewind",
      "description": "Rewind to a previous checkpoint (restore code, conversation, or both)",
      "category": "workspace"
    },
    {
      "command": "/memory",
      "description": "Edit EROSOLAR.md memory file (project context and preferences)",
      "category": "configuration"
    },
    {
      "command": "/vim",
      "description": "Toggle vim-style editing mode in the input",
      "category": "configuration"
    },
    {
      "command": "/output-style",
      "description": "Change response style (default, explanatory, learning, concise, custom)",
      "category": "configuration"
    },
    {
      "command": "/cost",
      "description": "Show detailed token usage and API cost breakdown",
      "category": "diagnostics"
    },
    {
      "command": "/usage",
      "description": "Show token and context usage statistics",
      "category": "diagnostics"
    },
    {
      "command": "/clear",
      "description": "Clear conversation history and start fresh",
      "category": "workspace"
    },
    {
      "command": "/resume",
      "description": "Resume a previous session by ID or pick from recent",
      "category": "workspace"
    },
    {
      "command": "/export",
      "description": "Export conversation history to a file",
      "category": "workspace"
    },
    {
      "command": "/security-review",
      "description": "Run a comprehensive security review",
      "category": "diagnostics"
    },
    {
      "command": "/bug",
      "description": "Report an issue or bug",
      "category": "other"
    },
    {
      "command": "/terminal-setup",
      "description": "Configure terminal keybindings (Shift+Enter for multi-line)",
      "category": "configuration"
    },
    {
      "command": "/permissions",
      "description": "Configure tool permissions (allow/deny rules)",
      "category": "configuration"
    },
    {
      "command": "/update",
      "description": "Check for updates and configure auto-update preference",
      "category": "configuration"
    }
  ],

  "capabilities": [
    {
      "id": "chat",
      "label": "Chat",
      "description": "Basic conversational capabilities"
    },
    {
      "id": "reasoning",
      "label": "Reasoning",
      "description": "Extended chain-of-thought reasoning capabilities"
    },
    {
      "id": "tools",
      "label": "Tool Use",
      "description": "Ability to call external tools and functions"
    },
    {
      "id": "streaming",
      "label": "Streaming",
      "description": "Support for streaming responses"
    },
    {
      "id": "multimodal",
      "label": "Multimodal",
      "description": "Support for images and other non-text inputs"
    }
  ],

  "metadata": {
    "schemaVersion": "1.0.0",
    "lastUpdated": "2024-11-24",
    "description": "This is the single source of truth for all agent configurations in the Erosolar CLI"
  }
}
